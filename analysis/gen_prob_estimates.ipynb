{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import os \n",
    "# spec paths \n",
    "\n",
    "data_name = 'toy'\n",
    "out_pred_fname = 'predictions'\n",
    "k = 2 \n",
    "\n",
    "# get file names for training and test set \n",
    "data_test_root = data_name+'_test'\n",
    "data_train_root = data_name+'_train'\n",
    "# construct all paths \n",
    "dict_test_path = os.path.join('..','data', data_test_root, 'vocab.pkl')\n",
    "dict_prob_path = os.path.join('..','data', data_train_root, 'vocab.pkl')\n",
    "text_path = os.path.join('..','data', data_test_root, 'data.npy')\n",
    "prob_path = os.path.join('..','data', data_test_root, 'probs.npy')\n",
    "out_pred_path = os.path.join('..','data', data_test_root, out_pred_fname + '.txt')\n",
    "\n",
    "\n",
    "def get_top_k_preds(k, prob_vec, prob_dict):     \n",
    "    idx_top_k = prob_vec.argsort()[-k:][::-1]\n",
    "    prob_top_k = prob_vec[idx_top_k]\n",
    "    return idx_top_k, prob_top_k\n",
    "\n",
    "# print test set text \n",
    "def print_test_set(n, text, vocab_test_dict): \n",
    "    temp = ''\n",
    "    for i in range(n):\n",
    "        temp += vocab_test_dict[text[i]] + ' '\n",
    "    print(temp)\n",
    "    \n",
    "def print_most_likely_preds(n, prob, vocab_prob_dict): \n",
    "    pred = ''\n",
    "    for i in range(n): \n",
    "        idx_top_k, prob_top_k = get_top_k_preds(k, prob[i,:], vocab_prob_dict) \n",
    "        most_likely_word = vocab_prob_dict[idx_top_k[0]]\n",
    "        pred += most_likely_word +' '\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dict that translates test set vs. probability estimates \n",
    "with open(dict_test_path, 'rb') as f:\n",
    "    vocab_test_dict = pickle.load(f)\n",
    "with open(dict_prob_path, 'rb') as f:\n",
    "    vocab_prob_dict = pickle.load(f)\n",
    "\n",
    "# load test set text and probability estimates \n",
    "text = np.load(text_path)\n",
    "prob = np.load(prob_path)\n",
    "\n",
    "# get min (pred set, test set) size \n",
    "n_test_words = np.shape(text)[0]\n",
    "n_preds = np.shape(prob)[0]\n",
    "n = np.min([n_test_words, n_preds])\n",
    "\n",
    "# print out the prediction \n",
    "with open(out_pred_path, \"w\") as out_pred_file:\n",
    "\n",
    "    # loop over all words \n",
    "    out_pred_file_text = ''\n",
    "    for i in range(n): \n",
    "        idx_top_k, prob_top_k = get_top_k_preds(k, prob[i,:], vocab_prob_dict) \n",
    "        words_top_k = []\n",
    "        for j in range(k): \n",
    "            words_top_k.append(vocab_prob_dict[idx_top_k[j]])\n",
    "        \n",
    "        curr_word = vocab_test_dict[text[i]]\n",
    "        out_pred_file_text += curr_word +' '+ str(words_top_k) +' '+ str(prob_top_k)+'\\n'\n",
    "        \n",
    "    out_pred_file.write(out_pred_file_text)    \n",
    "        \n",
    "# evaluate the goodness of top k predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
